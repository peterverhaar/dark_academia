{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install nltk\n",
        "!pip install stanza"
      ],
      "metadata": {
        "id": "54sGKkLeGh1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os.path import basename\n",
        "import string\n",
        "import operator\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "from os.path import join\n",
        "\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon', quiet=False)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import word_tokenize,sent_tokenize,pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "ana = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    new_list= []\n",
        "    for w in words:\n",
        "        if w.isalnum():\n",
        "            new_list.append( w )\n",
        "    return new_list\n",
        "\n",
        "def ptb_to_wordnet(PTT):\n",
        "\n",
        "    if PTT.startswith('J'):\n",
        "        ## Adjective\n",
        "        return 'a'\n",
        "    elif PTT.startswith('V'):\n",
        "        ## Verb\n",
        "        return 'v'\n",
        "    elif PTT.startswith('N') and not PTT.startswith('NNP'):\n",
        "        ## Noune\n",
        "        return 'n'\n",
        "    elif PTT.startswith('R'):\n",
        "        ## Adverb\n",
        "        return 'r'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def wordnet_hypernyms(token):\n",
        "    all_hypernyms = []\n",
        "\n",
        "    word_senses = wn.synsets(token)\n",
        "\n",
        "    hypernyms = lambda s: s.hypernyms()\n",
        "\n",
        "    for ws in word_senses:\n",
        "\n",
        "        hypernyms = [hyp.name() for hyp in list(ws.closure(hypernyms))]\n",
        "        for h in hypernyms:\n",
        "            all_hypernyms.append(h[0:h.index('.')])\n",
        "\n",
        "    return all_hypernyms\n",
        "\n",
        "def intersection(list1,list2):\n",
        "    return list(set(list1) & set(list2))\n",
        "\n",
        "\n",
        "def collocation( text , regex , distance ):\n",
        "\n",
        "    freq_c = dict()\n",
        "\n",
        "    sentences = sent_tokenize( text )\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        words = word_tokenize( sentence )\n",
        "        words = remove_punctuation(words)\n",
        "\n",
        "        for i,w in enumerate(words):\n",
        "            if re.search( regex , w , re.IGNORECASE ):\n",
        "                index_regex = i\n",
        "\n",
        "                for x in range( i - distance , i + distance ):\n",
        "                    if x >= 0 and x < len(words) and words[x].lower() != words[index_regex].lower():\n",
        "                        if len(words[x]) > 0:\n",
        "                            word = words[x].lower()\n",
        "                            freq_c[ word ] = freq_c.get( word , 0 ) + 1\n",
        "\n",
        "    return freq_c\n",
        "\n",
        "\n",
        "def download(directory,url):\n",
        "    response = requests.get(url)\n",
        "    if response:\n",
        "        file_name = basename(url)\n",
        "        out = open(join(directory,file_name),'w',encoding='utf-8')\n",
        "        out.write(response.text)\n",
        "        out.close()\n",
        "    else:\n",
        "      print('File cannot be downloaded')\n",
        "\n"
      ],
      "metadata": {
        "id": "j6R2JclRGYoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ids = {'29044': 'The Secret History',\n",
        " '30319086': 'If We Were Villains',\n",
        " '43263680': 'Ninth House',\n",
        " '50520939': 'The Atlas Six',\n",
        " '5297': 'The Picture Of Dorian Gray',\n",
        " '40874032': 'Vicious',\n",
        " '50548197': 'A Deadly Education',\n",
        " '50999821': 'A Lesson In Vengeance',\n",
        " '50623864': 'The Invisible Life Of Addie Larue',\n",
        " '11250317': 'The Song Of Achilles',\n",
        " '42815544': 'Bunny',\n",
        " '38633526': 'Vita Nostra',\n",
        " '23752941': 'Jane Eyre',\n",
        " '6185': 'Wuthering Heights',\n",
        " '17675462': 'The Raven Boys',\n",
        " '32571395': 'One Of Us Is Lying',\n",
        " '45300567': 'The Maidens',\n",
        " '2387172': 'Maurice',\n",
        " '22055262': 'A Darker Shade Of Magic',\n",
        " '29589074': 'Truly Devious',\n",
        " '35031085': 'Frankenstein',\n",
        " '55572506': 'A Discovery Of Witches',\n",
        " '50892240': 'They Never Learn',\n",
        " '211154709': 'King Street Run',\n",
        " '17333223': 'The Goldfinch',\n",
        " '485894': 'The Metamorphosis',\n",
        " '120274': 'The Lake Of Dead Languages',\n",
        " '23395105': 'Black Chalk',\n",
        " '6699637': 'The Magicians',\n",
        " '6514': 'The Bell Jar',\n",
        " '200704039': 'Society Of Lies',\n",
        " '63277381': 'The Fortune Seller',\n",
        " '57945316': 'Babel',\n",
        " '5941114': 'The Likeness',\n",
        " '43263485': 'The Furies',\n",
        " '61288950': 'The Cloisters',\n",
        " '34594037': 'Magic For Liars',\n",
        " '54468663': 'The Box In The Woods',\n",
        " '35154365': 'S T A G S',\n",
        " '38963039': 'People Like Us',\n",
        " '56239414': 'Clara And The Devil',\n",
        " '12224817': 'The Year Of The Gadfly',\n",
        " '44552089': 'A Lesson In Thorns',\n",
        " '53290204': 'Summer Sons',\n",
        " '41217434': 'Killing November',\n",
        " '16319': 'The Body In The Library',\n",
        " '52450064': 'The Betrayals',\n",
        " '6656': 'The Divine Comedy',\n",
        " '1556093': 'Ghost Stories Of An Antiquary',\n",
        " '41054085': 'Drawer 7',\n",
        " '7713486': 'Skippy Dies',\n",
        " '60881270': 'Laertes',\n",
        " '126917855': 'When We Were Silent',\n",
        " '197220654': 'The Book Of Dark Academia',\n",
        " '219789574': 'The Sunken Town',\n",
        " '240901431': 'The Picture Of Dorian Gray Typos Free Text Clean Copy For A Flowless Re',\n",
        " '82694054': 'Gothic Revival',\n",
        " '46259991': 'All Girls',\n",
        " '16244761': 'Extinction Point',\n",
        " '56969395': 'In The Ballroom With The Candlestick',\n",
        " '59787427': 'Over My Dead Body',\n",
        " '650775': 'Collected Ghost Stories',\n",
        " '138134': 'The Complete Poems',\n",
        " '54926634': 'Shelter For The Damned',\n",
        " '44279110': 'My Year Of Rest And Relaxation',\n",
        " '11623': 'The Unabridged Journals Of Sylvia Plath',\n",
        " '58470435': 'Psycho',\n",
        " '88340': 'Letters To Milena',\n",
        " '58897310': 'The Devil Makes Three',\n",
        " '11378763': 'The Book Of Blood And Shadow',\n",
        " '35402204': 'The Mystery Of Black Hollow Lane',\n",
        " '36467791': 'L Altra Grace',\n",
        " '61484909': 'Where Sleeping Girls Lie',\n",
        " '127279986': 'Hell Bent',\n",
        " '49798488': 'Hunting November',\n",
        " '58416952': 'The Will Of The Many',\n",
        " '7534093': 'The Lessons',\n",
        " '52439531': 'The Inheritance Games',\n",
        " '39964740': 'The Binding',\n",
        " '49535011': 'Madam',\n",
        " '45184284': 'What We Devour',\n",
        " '42379216': 'The Truants',\n",
        " '50398': 'Northanger Abbey',\n",
        " '12346651': 'The Picture Of Dorian Grey',\n",
        " '67238': 'Dead Poets Society',\n",
        " '75302266': 'A Study In Drowning',\n",
        " '101141871': 'Curious Tides',\n",
        " '6101718': 'The Magicians',\n",
        " '8667848': 'A Discovery Of Witches',\n",
        " '26856502': 'Vengeful',\n",
        " '59345249': 'The It Girl',\n",
        " '62679690': 'The Night It Ended',\n",
        " '215366272': 'Unhallowed Halls',\n",
        " '219513031': 'Academy Of Villains',\n",
        " '78816533': 'All That Consumes Us',\n",
        " '15108': 'Gentlemen And Players',\n",
        " '223138225': 'Lessons In Loyalty   Aphrodite Adonis',\n",
        " '61884783': 'Boys In The Valley',\n",
        " '234344800': 'Lessons In Trickery   Hekate Hermes',\n",
        " '61331501': 'Assassin Of Reality',\n",
        " '50485649': 'In My Dreams I Hold A Knife',\n",
        " '50892212': 'These Violent Delights',\n",
        " '43575115': 'The Starless Sea',\n",
        " '42036538': 'Gideon The Ninth',\n",
        " '50202953': 'Piranesi',\n",
        " '49203397': 'These Violent Delights',\n",
        " '9460487': 'Miss Peregrine S Home For Peculiar Children',\n",
        " '30236962': 'The Historian',\n",
        " '6334': 'Never Let Me Go',\n",
        " '42603984': 'Ace Of Spades',\n",
        " '51934838': 'Catherine House',\n",
        " '166997': 'Stoner',\n",
        " '48037': 'Carmilla',\n",
        " '62022': 'The Queen S Gambit',\n",
        " '41219': 'Possession',\n",
        " '56383038': 'Never Saw Me Coming',\n",
        " '124948406': 'They Never Learn',\n",
        " '50496875': 'Plain Bad Heroines',\n",
        " '3103': 'Maurice',\n",
        " '57800389': 'Mexican Gothic',\n",
        " '11297': 'Norwegian Wood',\n",
        " '15102': 'Gentlemen And Players',\n",
        " '42505366': 'Wilder Girls',\n",
        " '60652997': 'Hell Bent',\n",
        " '50892338': 'Legendborn',\n",
        " '57912066': 'The Atlas Paradox',\n",
        " '210223811': 'Katabasis',\n",
        " '29939230': 'A Conjuring Of Light',\n",
        " '208430658': 'Blood Over Bright Haven',\n",
        " '48896122': 'The Ivies',\n",
        " '35356380': 'People Like Us',\n",
        " '52778487': 'How We Fall Apart',\n",
        " '131177': 'Hangsaman',\n",
        " '35403058': 'City Of Ghosts',\n",
        " '207567816': 'The Scholar And The Last Faerie Door',\n",
        " '54578759': 'Have You Seen Me',\n",
        " '20764879': 'A Gathering Of Shadows',\n",
        " '200982373': 'Don T Let The Forest In',\n",
        " '21874813': 'As Chimney Sweepers Come To Dust',\n",
        " '102885': 'Waking The Moon',\n",
        " '1629601': 'The Disreputable History Of Frankie Landau Banks',\n",
        " '32895291': 'The Lying Game',\n",
        " '61054804': 'The Cloisters',\n",
        " '42614700': 'Campusland',\n",
        " '57917042': 'Anatomy',\n",
        " '10997': 'The Basic Eight',\n",
        " '1090888': 'Gaudy Night',\n",
        " '52379865': 'For Your Own Good',\n",
        " '13069261': 'The Bellwether Revivals',\n",
        " '64414866': 'An Education In Malice',\n",
        " '52179715': 'Ghosts Of Harvard',\n",
        " '55858638': 'The Golden Enclaves',\n",
        " '27068793': 'Ink And Bone',\n",
        " '44084762': 'Our Violent Ends',\n",
        " '46159063': 'The Betrayals',\n",
        " '634771': 'A Great And Terrible Beauty',\n",
        " '18431': 'The Rule Of Four',\n",
        " '229003381': 'Nightshade',\n",
        " '209563735': 'Death In The Spires',\n",
        " '16143347': 'We Were Liars',\n",
        " '40033006': 'The 7 Deaths Of Evelyn Hardcastle',\n",
        " '43232967': 'Where Sleeping Girls Lie',\n",
        " '55559887': 'The Last Graduate',\n",
        " '43744294': 'The Swallows',\n",
        " '791345': 'Picnic At Hanging Rock',\n",
        " '57426932': 'Gothikana',\n",
        " '210365385': 'The Resurrectionist',\n",
        " '35965482': 'Middlegame',\n",
        " '53063341': 'The Inheritance Games',\n",
        " '48915818': 'The Death Of Jane Lawrence',\n",
        " '174146852': 'A Dark And Drowning Tide',\n",
        " '63874788': 'In These Hallowed Halls',\n",
        " '18490': 'Frankenstein',\n",
        " '8852': 'Macbeth',\n",
        " '1381': 'The Odyssey',\n",
        " '10210': 'Jane Eyre',\n",
        " '1549': 'Antigone Oedipus The King Electra',\n",
        " '7144': 'Crime And Punishment',\n",
        " '1371': 'The Iliad',\n",
        " '112204': 'The Complete Poems Of Emily Dickinson',\n",
        " '18135': 'Romeo And Juliet',\n",
        " '17245': 'Dracula',\n",
        " '209828': 'Sappho',\n",
        " '386270': 'Selected Poems',\n",
        " '1473': 'Medea And Other Plays',\n",
        " '1715': 'Metamorphoses',\n",
        " '30289': 'The Republic',\n",
        " '81779': 'The Symposium',\n",
        " '2175': 'Madame Bovary',\n",
        " '1420': 'Hamlet',\n",
        " '223394': 'The Complete Poems',\n",
        " '119239': 'Selected Poems',\n",
        " '18386': 'The Death Of Ivan Ilych',\n",
        " '15997': 'Paradise Lost',\n",
        " '12938': 'King Lear',\n",
        " '499709': 'The Hidden Words Of Bah U Ll H',\n",
        " '17717': 'Labyrinths',\n",
        " '18495': 'The Monsters',\n",
        " '52357': 'Beowulf',\n",
        " '4934': 'The Brothers Karamazov',\n",
        " '21527802': 'Pale Fire',\n",
        " '199009': 'The Oxford Book Of English Verse',\n",
        " '12914': 'The Aeneid',\n",
        " '14942': 'Mrs Dalloway',\n",
        " '92308': 'The Importance Of Being Earnest And Other Plays',\n",
        " '13270': 'Poetics',\n",
        " '9438': 'The Basic Works Of Aristotle',\n",
        " '142247': 'Russian Short Stories From Pushkin To Buida',\n",
        " '1519': 'The Oresteia',\n",
        " '2368849': 'The Ante Room',\n",
        " '5678929': 'Bacchae And Other Plays',\n",
        " '36006882': 'De Profundis The Ballad Of Reading Gaol Other Writings',\n",
        " '28101721': 'The Greeks',\n",
        " '26252': 'The Enneads',\n",
        " '67376': 'The Book Of Love',\n",
        " '103159': 'The Forsyte Saga',\n",
        " '31491': 'The Rainbow',\n",
        " '128453': 'Complete Works',\n",
        " '169524': 'Twenty Thousand Streets Under The Sky',\n",
        " '1720478': 'Cie Wiatru',\n",
        " '1220032': 'The Rector S Daughter',\n",
        " '782982': 'The Lonely Passion Of Judith Hearne',\n",
        " '53022': 'The Collected Poems Of W B Yeats',\n",
        " '732562': 'The Rime Of The Ancient Mariner',\n",
        " '609155': 'Leaves Of Grass And Other Writings',\n",
        " '37901616': 'The Golden Treasury',\n",
        " '214229': 'Lives Of The Poets',\n",
        " '23291': 'Dubliners',\n",
        " '2090229': 'The Works Of Elizabeth Barrett Browning',\n",
        " '59716': 'To The Lighthouse',\n",
        " '32874746': 'If We Were Villains',\n",
        " '53285047': 'Bunny',\n",
        " '1914973': 'The Likeness',\n",
        " '36476218': 'She Was The Quiet One',\n",
        " '5148': 'A Separate Peace',\n",
        " '134915247': 'Babel',\n",
        " '60058055': 'The Golden Enclaves',\n",
        " '53181134': 'Mary Everything',\n",
        " '41817363': 'Tell Me Everything',\n",
        " '87365806': 'A Darker Mischief',\n",
        " '198983055': 'Curious Tides',\n",
        " '161755665': 'The Favourites',\n",
        " '238142783': 'The Quiet Girls',\n",
        " '46259689': 'Oligarchy',\n",
        " '61885117': 'This Is The Way The World Ends',\n",
        " '221142749': 'Stranger Skies',\n",
        " '198209301': 'Secrets Of The Catalogue',\n",
        " '136470356': 'Nocticadia',\n",
        " '36381099': 'All These Beautiful Strangers',\n",
        " '210446552': 'Foundation',\n",
        " '222376804': 'Oxford Blood',\n",
        " '214416570': 'The Otherwhere Post',\n",
        " '215151274': 'Love Immortal'}"
      ],
      "metadata": {
        "id": "d7dUXVSuhIYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download('','https://raw.githubusercontent.com/peterverhaar/dark_academia/refs/heads/main/review_files.txt')\n"
      ],
      "metadata": {
        "id": "mFvfUTXTCXcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files = []\n",
        "review_files = open('review_files.txt',encoding='utf-8')\n",
        "for file in review_files:\n",
        "  if re.search('txt$',file):\n",
        "    txt_files.append(file.strip())\n",
        "\n"
      ],
      "metadata": {
        "id": "SXWFDRx7CjaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://raw.githubusercontent.com/peterverhaar/dark_academia/refs/heads/main/Reviews/'\n",
        "\n",
        "txt_dir = 'Reviews'\n",
        "if not os.path.isdir(txt_dir):\n",
        "    os.mkdir(txt_dir)\n",
        "\n",
        "for txt in txt_files:\n",
        "  review_url = f'{base_url}{txt}'\n",
        "  download(txt_dir,review_url)"
      ],
      "metadata": {
        "id": "6hEc8hHmF6ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'Lexicon'\n",
        "if not os.path.isdir(dir):\n",
        "    os.mkdir(dir)\n",
        "\n",
        "base_url = 'https://raw.githubusercontent.com/peterverhaar/dark_academia/refs/heads/main/Lexicon/'\n",
        "\n",
        "lexicon_files = [\n",
        "    'academia.txt',\n",
        "    'literature_and_culture.txt',\n",
        "    'mood.txt',\n",
        "    'objects.txt',\n",
        "    'spaces.txt'\n",
        "]\n",
        "\n",
        "\n",
        "for l in lexicon_files:\n",
        "    topic = l[ : l.rindex('.') ]\n",
        "    response = requests.get( base_url + l)\n",
        "    words = []\n",
        "    if response:\n",
        "        response.encoding = 'utf-8'\n",
        "        out = open( os.path.join( dir , l ) , 'w' , encoding = 'utf-8' )\n",
        "        out.write( response.text )\n",
        "        out.close()\n",
        "\n",
        "print('Lexicons have been downloaded!')\n",
        "\n",
        "\n",
        "\n",
        "lexicons = dict()\n",
        "\n",
        "\n",
        "for file in os.listdir(dir):\n",
        "    if re.search(r'txt$',file):\n",
        "\n",
        "        topic = re.sub( r'\\.txt$','',file )\n",
        "        words = []\n",
        "\n",
        "        with open( join(dir,file) , encoding = 'utf-8' ) as file_handler:\n",
        "            for l in file_handler:\n",
        "                if re.search( r'\\w' , l ):\n",
        "                    words.append(l.strip().lower())\n",
        "\n",
        "        lexicons[topic] = words\n"
      ],
      "metadata": {
        "id": "fUT8diAsJG1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_directory = 'CSV'\n",
        "if not os.path.exists(csv_directory):\n",
        "    os.makedirs(csv_directory)\n",
        "\n",
        "\n",
        "for txt_file in txt_files:\n",
        "\n",
        "  csv = open( join( csv_directory , f'{ re.sub('[.]txt$','',txt_file) }.csv' ) , 'w' , encoding = 'utf-8' )\n",
        "  csv.write('category,count\\n')\n",
        "\n",
        "  path = join(txt_dir,txt_file)\n",
        "\n",
        "  with open(path,encoding='utf-8') as fh:\n",
        "\n",
        "      full_text = fh.read()\n",
        "      words = word_tokenize(full_text)\n",
        "      words = remove_punctuation(words)\n",
        "      freq = Counter(words)\n",
        "      tokens = len(words)\n",
        "\n",
        "      if tokens > 0:\n",
        "\n",
        "          for l in lexicons:\n",
        "              csv.write(f'{l},')\n",
        "\n",
        "              count_occurrences = 0\n",
        "              for word in l:\n",
        "                  count_occurrences += freq.get(word.lower(),0)\n",
        "              csv.write( f'{ count_occurrences / tokens}\\n' )\n",
        "\n",
        "          csv.write('\\n')\n",
        "\n",
        "  csv.close()"
      ],
      "metadata": {
        "id": "MOF1LMiBIaHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "graph_directory = 'Graphs'\n",
        "if not os.path.exists(graph_directory):\n",
        "    os.makedirs(graph_directory)\n",
        "\n",
        "for csv in os.listdir(csv_directory):\n",
        "\n",
        "  try:\n",
        "\n",
        "    title = re.sub('[.]csv$','',csv)\n",
        "    title = title[ len('review_')+1:]\n",
        "    title = book_ids[title]\n",
        "    print(title)\n",
        "\n",
        "    df = pd.read_csv(join(csv_directory,csv))\n",
        "\n",
        "    fig = plt.figure( figsize=( 7 ,6 ) )\n",
        "    ax = plt.axes()\n",
        "\n",
        "    x = 'category'\n",
        "    y = 'count'\n",
        "\n",
        "    bar_width = 0.45\n",
        "    opacity = 0.8\n",
        "\n",
        "    ax.bar( df[x] , df[y] , width = bar_width, alpha = opacity , color = '#fcc11c')\n",
        "\n",
        "    plt.xticks(rotation= 75)\n",
        "\n",
        "    ax.set_xlabel('Category' , fontsize= 12)\n",
        "    ax.set_ylabel('Relative frequency' , fontsize = 12 )\n",
        "    ax.set_title( title.title() , fontsize=20 )\n",
        "\n",
        "    plt.ylim(0, 0.15)\n",
        "    path = join( graph_directory , f'{re.sub(r'\\s+','_',title.lower())}.png')\n",
        "    print(path)\n",
        "    plt.savefig( path ,dpi=300)\n",
        "  except:\n",
        "    print(f'Problem with {csv}')"
      ],
      "metadata": {
        "id": "IR-elvaoF9XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for file in os.listdir(graph_directory):\n",
        "  files.download(join(graph_directory,file))\n",
        ""
      ],
      "metadata": {
        "id": "AnWP3-wBlby-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28hmCoo1m4Bq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}